{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdN8/RXD/hbAcmW4z8qO91",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/ML-Python/blob/main/python_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vhTfpo5mmUZ"
      },
      "outputs": [],
      "source": [
        "#svm\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "svc = svm.SVC(probability=True, random_state=random_state)\n",
        "clf = GridSearchCV(svc, parameters)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(clf.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#smote\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Entrenar el modelo SVM\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "p72DoTO3mpeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#undersampling\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar RandomUnderSampler al conjunto de entrenamiento\n",
        "rus = RandomUnderSampler(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(svm.SVC(kernel='linear', probability=True, random_state=random_state), param_grid, refit=True)\n",
        "grid.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "sQmvjPzmnIJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar ADASYN al conjunto de entrenamiento\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(svm.SVC(kernel='linear', probability=True, random_state=random_state), param_grid, refit=True)\n",
        "grid.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "jVm7_ta7nYyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar TomekLinks al conjunto de entrenamiento\n",
        "tl = TomekLinks()\n",
        "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
        "\n",
        "# Definir los parámetros para la búsqueda en grilla\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "\n",
        "# Crear el objeto GridSearchCV\n",
        "grid_search = GridSearchCV(svm.SVC(probability=True, random_state=random_state), param_grid, cv=5)\n",
        "\n",
        "# Entrenar el modelo SVM con búsqueda en grilla\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid_search.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid_search.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "3MlMop7Rnn-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}