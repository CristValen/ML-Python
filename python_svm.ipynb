{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS8fhJVymA3dCaqqYAA5Xj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/ML-Python/blob/main/python_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vhTfpo5mmUZ"
      },
      "outputs": [],
      "source": [
        "#svm\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Estandarizar las variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "svc = svm.SVC(probability=True, random_state=random_state)\n",
        "clf = GridSearchCV(svc, parameters)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test_scaled)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(clf.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Estandarizar las variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Entrenar el modelo SVM\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test_scaled)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "p72DoTO3mpeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#undersampling\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar RandomUnderSampler al conjunto de entrenamiento\n",
        "rus = RandomUnderSampler(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear una instancia de StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar el escalador a los datos de entrenamiento\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transformar los datos de entrenamiento y prueba\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(svm.SVC(kernel='linear', probability=True, random_state=random_state), param_grid, refit=True)\n",
        "grid.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQmvjPzmnIJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar ADASYN al conjunto de entrenamiento\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear una instancia de StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar el escalador a los datos de entrenamiento\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transformar los datos de entrenamiento y prueba\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Entrenar el modelo SVM con validación cruzada\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(svm.SVC(kernel='linear', probability=True, random_state=random_state), param_grid, refit=True)\n",
        "grid.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jVm7_ta7nYyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 42\n",
        "\n",
        "# Convertir el DataFrame de PySpark a Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Dividir el conjunto de datos en train y test\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Aplicar TomekLinks al conjunto de entrenamiento\n",
        "tl = TomekLinks()\n",
        "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear una instancia de StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar el escalador a los datos de entrenamiento\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transformar los datos de entrenamiento y prueba\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir los parámetros para la búsqueda en grilla\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "\n",
        "# Crear el objeto GridSearchCV\n",
        "grid_search = GridSearchCV(svm.SVC(probability=True, random_state=random_state), param_grid, cv=5)\n",
        "\n",
        "# Entrenar el modelo SVM con búsqueda en grilla\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predecir valores para el conjunto de test\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "fpr, tpr, thresholds = roc_curve(y_test, grid_search.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Obtener las 10 variables más importantes del modelo\n",
        "feature_importances = pd.DataFrame(grid_search.best_estimator_.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "3MlMop7Rnn-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sin cross validation\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 42\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Standardize the variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model without cross-validation\n",
        "svc = svm.SVC(probability=True, random_state=random_state)\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = svc.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, svc.predict_proba(X_test_scaled)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(svc.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kLC_hmQw6_E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 42\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Standardize the variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to the training set\n",
        "sm = SMOTE(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Train the SVM model without cross-validation\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test_scaled)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "fK3m-f5D73Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 42\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply RandomUnderSampler to the training set\n",
        "rus = RandomUnderSampler(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model without cross-validation\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "GzRu8wmc8ZAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 42\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply ADASYN to the training set\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model without cross-validation\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "55hF-yWA8ZH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 42\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malos_Dias_tot', axis=1)\n",
        "y = pandas_df['Malos_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply TomekLinks to the training set\n",
        "tl = TomekLinks()\n",
        "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model without cross-validation\n",
        "clf = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.coef_[0], index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "je6qKRmA8ZKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gasHXNhX8ZN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UghiLkLQ8ZSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest model without cross-validation\n",
        "clf = RandomForestClassifier(random_state=random_state)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "hr0MIUTB6rDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply SMOTE to the training set\n",
        "sm = SMOTE(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest model without cross-validation\n",
        "clf = RandomForestClassifier(random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "iorfuzKbDm8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply RandomUnderSampler to the training set\n",
        "rus = RandomUnderSampler(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest model without cross-validation\n",
        "clf = RandomForestClassifier(random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "pmx9xDOQDnPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Apply ADASYN to the training set\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_resampled)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Random Forest model without cross-validation\n",
        "clf = RandomForestClassifier(random_state=random_state)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "vlz_5d1wDnVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create an instance of StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform the training and test data\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "clf = DecisionTreeClassifier(random_state=random_state)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "ks = np.max(tpr - fpr)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "feature_importances = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "FNjA5XJKDnYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###pyspark svm\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df_2.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate KS statistic using BinaryClassificationEvaluator with areaUnderPR metric\n",
        "evaluator.setMetricName('areaUnderPR')\n",
        "ks = evaluator.evaluate(predictions)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# Calculate and display ROC curve\n",
        "pdf = predictions.select('Malo_Dias_tot', 'rawPrediction').toPandas()\n",
        "fpr, tpr, thresholds = roc_curve(pdf['Malo_Dias_tot'], pdf['rawPrediction'].apply(lambda x: x[1]))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KPaUVr82JJez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df_2.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Perform random undersampling to balance the classes in the training data\n",
        "majority_class = train.groupby('Malo_Dias_tot').count().orderBy('count', ascending=False).first()[0]\n",
        "minority_class_count = train.filter(train.Malo_Dias_tot != majority_class).count()\n",
        "undersampled_train = train.filter(train.Malo_Dias_tot == majority_class).sample(False, float(minority_class_count) / train.filter(train.Malo_Dias_tot == majority_class).count(), seed=random_state)\n",
        "undersampled_train = undersampled_train.union(train.filter(train.Malo_Dias_tot != majority_class))\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(undersampled_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate KS statistic using BinaryClassificationEvaluator with areaUnderPR metric\n",
        "evaluator.setMetricName('areaUnderPR')\n",
        "ks = evaluator.evaluate(predictions)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# Calculate and display ROC curve\n",
        "pdf = predictions.select('Malo_Dias_tot', 'rawPrediction').toPandas()\n",
        "fpr, tpr, thresholds = roc_curve(pdf['Malo_Dias_tot'], pdf['rawPrediction'].apply(lambda x: x[1]))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_ASF38lv79I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df_2.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Perform ADASYN oversampling to balance the classes in the training data\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "train_pd = train.toPandas()\n",
        "X_resampled, y_resampled = adasyn.fit_resample(train_pd[feature_cols], train_pd['Malo_Dias_tot'])\n",
        "oversampled_train = spark.createDataFrame(pd.concat([X_resampled, y_resampled], axis=1))\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(oversampled_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate KS statistic using BinaryClassificationEvaluator with areaUnderPR metric\n",
        "evaluator.setMetricName('areaUnderPR')\n",
        "ks = evaluator.evaluate(predictions)\n",
        "print(f'KS: {ks}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# Calculate and display ROC curve\n",
        "pdf = predictions.select('Malo_Dias_tot', 'rawPrediction').toPandas()\n",
        "fpr, tpr, thresholds = roc_curve(pdf['Malo_Dias_tot'], pdf['rawPrediction'].apply(lambda x: x[1]))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XC8aSRh43lis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Convertir los datos de entrenamiento a un DataFrame de Pandas\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = train_pd.columns.tolist()\n",
        "features.remove('label')\n",
        "\n",
        "# Aplicar remuestreo ADASYN\n",
        "adasyn = ADASYN(random_state=12345)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(train_pd[features], train_pd['label'])\n",
        "\n",
        "# Convertir los datos remuestreados de nuevo a un DataFrame de PySpark\n",
        "train_resampled = spark.createDataFrame(\n",
        "    pd.concat([pd.DataFrame(X_resampled, columns=features), pd.Series(y_resampled, name='label')], axis=1)\n",
        ")\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=12345)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento remuestreados\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Obtener las características más importantes\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Características más importantes:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qopQfeAWVFw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from pyspark.ml.linalg import Vectors\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Convertir los datos de entrenamiento a un DataFrame de Pandas\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = train_pd.columns.tolist()\n",
        "features.remove('label')\n",
        "\n",
        "# Aplicar remuestreo ADASYN\n",
        "adasyn = ADASYN(random_state=12345)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(train_pd[features], train_pd['label'])\n",
        "\n",
        "# Convertir los datos remuestreados de nuevo a un DataFrame de PySpark\n",
        "train_resampled = spark.createDataFrame(\n",
        "    pd.concat([pd.DataFrame(X_resampled, columns=features), pd.Series(y_resampled, name='label')], axis=1)\n",
        ")\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=12345)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento remuestreados\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Obtener las características más importantes\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Características más importantes:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Calcular el número de ejemplos en cada clase antes y después del remuestreo\n",
        "original_counts = train_pd['label'].value_counts().sort_index()\n",
        "resampled_counts = pd.Series(y_resampled).value_counts().sort_index()\n",
        "\n",
        "# Crear un gráfico de barras para visualizar el número de ejemplos en cada clase\n",
        "x = np.arange(len(original_counts))\n",
        "width = 0.35\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, original_counts, width, label='Original data')\n",
        "rects2 = ax.bar(x + width/2, resampled_counts, width, label='ADASYN resampled data')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(original_counts.index)\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G2vXYjG2efbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n"
      ],
      "metadata": {
        "id": "xzNdqUz-iZ5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###smote svm\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Convertir el DataFrame de PySpark en un DataFrame de Pandas\n",
        "df8_pd = df_2.toPandas()\n",
        "\n",
        "# Separar las características y la etiqueta\n",
        "X = df8_pd.drop('Malo_Dias_tot', axis=1)\n",
        "y = df8_pd['Malo_Dias_tot']\n",
        "\n",
        "# Aplicar SMOTE a los datos\n",
        "smote = SMOTE(random_state=0)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Convertir los datos remuestreados en un DataFrame de PySpark\n",
        "data = np.hstack((X_resampled, y_resampled.reshape(-1, 1)))\n",
        "columns = X.columns.tolist() + ['label']\n",
        "df8 = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Obtener los coeficientes del modelo SVM\n",
        "coefficients = model.bestModel.stages[-1].coefficients.toArray()\n",
        "\n",
        "# Obtener las 10 características más importantes sin utilizar la función abs() incorporada de Python\n",
        "important_features = sorted(zip(coefficients, features), key=lambda x: x[0] if x[0] >= 0 else -x[0], reverse=True)[:10]\n",
        "\n",
        "# Mostrar las 10 características más importantes\n",
        "print(\"Las 10 características más importantes (en orden de importancia):\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RyVq8uD0xUBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## svm sin remuestreo\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Obtener los coeficientes del modelo SVM\n",
        "coefficients = model.bestModel.stages[-1].coefficients.toArray()\n",
        "\n",
        "# Obtener las 10 características más importantes sin utilizar la función abs() incorporada de Python\n",
        "important_features = sorted(zip(coefficients, features), key=lambda x: x[0] if x[0] >= 0 else -x[0], reverse=True)[:10]\n",
        "\n",
        "# Mostrar las 10 características más importantes\n",
        "print(\"Las 10 características más importantes (en orden de importancia):\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "2voS93Ibxo_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Convertir los datos de entrenamiento a un DataFrame de Pandas\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = train_pd.columns.tolist()\n",
        "features.remove('label')\n",
        "\n",
        "# Aplicar remuestreo determinista undersampling\n",
        "rus = RandomUnderSampler(random_state=12345)\n",
        "X_resampled, y_resampled = rus.fit_resample(train_pd[features], train_pd['label'])\n",
        "\n",
        "# Convertir los datos remuestreados de nuevo a un DataFrame de PySpark\n",
        "train_resampled = spark.createDataFrame(\n",
        "    pd.concat([pd.DataFrame(X_resampled, columns=features), pd.Series(y_resampled, name='label')], axis=1)\n",
        ")\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento remuestreados\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Obtener los coeficientes del modelo SVM\n",
        "coefficients = model.bestModel.stages[-1].coefficients.toArray()\n",
        "\n",
        "# Obtener las 10 características más importantes\n",
        "important_features = sorted(zip(coefficients, features), key=lambda x: abs(x[0]), reverse=True)[:10]\n",
        "\n",
        "# Mostrar las 10 características más importantes\n",
        "print(\"Las 10 características más importantes (en orden de importancia):\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "tctz4Dymx9tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Convertir los datos de entrenamiento a un DataFrame de Pandas\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = train_pd.columns.tolist()\n",
        "features.remove('label')\n",
        "\n",
        "# Aplicar remuestreo ADASYN\n",
        "adasyn = ADASYN(random_state=12345)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(train_pd[features], train_pd['label'])\n",
        "\n",
        "# Convertir los datos remuestreados de nuevo a un DataFrame de PySpark\n",
        "train_resampled = spark.createDataFrame(\n",
        "    pd.concat([pd.DataFrame(X_resampled, columns=features), pd.Series(y_resampled, name='label')], axis=1)\n",
        ")\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento remuestreados\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Obtener los coeficientes del modelo SVM\n",
        "coefficients = model.bestModel.stages[-1].coefficients.toArray()\n",
        "\n",
        "# Obtener las 10 características más importantes\n",
        "important_features = sorted(zip(coefficients, features), key=lambda x: abs(x[0]), reverse=True)[:10]\n",
        "\n",
        "# Mostrar las 10 características más importantes\n",
        "print(\"Las 10 características más importantes (en orden de importancia):\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "8oSDxQlI0ZM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Convertir los datos de entrenamiento a un DataFrame de Pandas\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = train_pd.columns.tolist()\n",
        "features.remove('label')\n",
        "\n",
        "# Aplicar remuestreo con Tomek Links\n",
        "tl = TomekLinks()\n",
        "X_resampled, y_resampled = tl.fit_resample(train_pd[features], train_pd['label'])\n",
        "\n",
        "# Convertir los datos remuestreados de nuevo a un DataFrame de PySpark\n",
        "train_resampled = spark.createDataFrame(\n",
        "    pd.concat([pd.DataFrame(X_resampled, columns=features), pd.Series(y_resampled, name='label')], axis=1)\n",
        ")\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Máquina de Vectores de Soporte\n",
        "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, svm])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(svm.regParam, [0.1, 0.01]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, seed=0)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento remuestreados\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC, recall, F1 y accuracy\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1: {f1:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Calcular el estadístico KS\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob']=grouped.max().probability\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "prob_udf=udf(lambda v:float(v[1]),DoubleType())\n",
        "predictions=predictions.withColumn('probability',prob_udf('probability'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Obtener los coeficientes del modelo SVM\n",
        "coefficients = model.bestModel.stages[-1].coefficients.toArray()\n",
        "\n",
        "# Obtener las 10 características más importantes\n",
        "important_features = sorted(zip(coefficients, features), key=lambda x: abs(x[0]), reverse=True)[:10]\n",
        "\n",
        "# Mostrar las 10 características más importantes\n",
        "print(\"Las 10 características más importantes (en orden de importancia):\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "HxIw50Yb1Ni0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df_2.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['Malo_Dias_tot']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['Malo_Dias_tot']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "AHqSudUM8M2p",
        "outputId": "bee88d7f-92f4-4d41-b2a4-fa3d2e8bb079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-69b6b0dfe616>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convertir el DataFrame de PySpark en un DataFrame de Pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf8_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Separar las características y la etiqueta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Separate the features and the label\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "\n",
        "# Apply SMOTE to the data\n",
        "smote = SMOTE(random_state=random_state)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data to a PySpark DataFrame\n",
        "resampled_data = spark.createDataFrame(pd.concat([X_resampled, y_resampled], axis=1))\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = resampled_data.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['Malo_Dias_tot']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['Malo_Dias_tot']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "DDlZGxkncjss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the PySpark DataFrame to Pandas\n",
        "pandas_df = df_2.toPandas()\n",
        "\n",
        "# Separate the features and the label\n",
        "X = pandas_df.drop('Malo_Dias_tot', axis=1)\n",
        "y = pandas_df['Malo_Dias_tot']\n",
        "\n",
        "# Apply ADASYN to the data\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data to a PySpark DataFrame\n",
        "resampled_data = spark.createDataFrame(pd.concat([X_resampled, y_resampled], axis=1))\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = resampled_data.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['Malo_Dias_tot']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['Malo_Dias_tot']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "uQd3XykTiOvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.sql.functions import col, rand, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Calculate the number of examples in each class\n",
        "class_counts = df_2.groupBy('Malo_Dias_tot').count().collect()\n",
        "num_positives = class_counts[1][1]\n",
        "num_negatives = class_counts[0][1]\n",
        "\n",
        "# Calculate the number of negative examples to keep\n",
        "num_to_keep = int(num_positives / num_negatives * num_negatives)\n",
        "\n",
        "# Select a random subset of the majority class\n",
        "majority_subset = df_2.filter(col('Malo_Dias_tot') == 0).orderBy(rand(seed=random_state)).limit(num_to_keep)\n",
        "\n",
        "# Combine the majority subset with the minority class to create the undersampled data\n",
        "undersampled_data = majority_subset.union(df_2.filter(col('Malo_Dias_tot') == 1))\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = undersampled_data.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Create a StandardScaler to standardize the features\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Train the Support Vector Machine model without cross-validation\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Create a pipeline to chain the assembler, scaler and SVM together\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['Malo_Dias_tot']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['Malo_Dias_tot']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].coefficients.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "HSBrPvcmkYGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df_2.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(featuresCol='features', labelCol='Malo_Dias_tot', seed=random_state)\n",
        "\n",
        "# Create a pipeline to chain the assembler and Decision Tree together\n",
        "pipeline = Pipeline(stages=[assembler, dt])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Define a UDF to extract the second element of the probability vector\n",
        "probability_udf = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Add a 'score' column to the predictions DataFrame\n",
        "predictions = predictions.withColumn('score', probability_udf('probability'))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = predictions.select('Malo_Dias_tot', 'score').toPandas()\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].featureImportances.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "drj57-NL3Tiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=random_state)\n",
        "\n",
        "# Fit the SMOTE object to the data and transform the data\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data back to a PySpark DataFrame\n",
        "data_resampled = spark.createDataFrame(pd.DataFrame(X_resampled, columns=feature_cols))\n",
        "labels_resampled = spark.createDataFrame(pd.DataFrame(y_resampled, columns=['Malo_Dias_tot']))\n",
        "data_resampled = data_resampled.crossJoin(labels_resampled)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = data_resampled.randomSplit([0.8, 0.2], seed=random_state)\n",
        "\n",
        "# Create a VectorAssembler to combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(featuresCol='features', labelCol='Malo_Dias_tot', seed=random_state)\n",
        "\n",
        "# Create a pipeline to chain the assembler and Decision Tree together\n",
        "pipeline = Pipeline(stages=[assembler, dt])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# Predict values for the test set\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate metrics\n",
        "tp = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 1)].count()\n",
        "tn = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 0)].count()\n",
        "fp = predictions[(predictions.Malo_Dias_tot == 0) & (predictions.prediction == 1)].count()\n",
        "fn = predictions[(predictions.Malo_Dias_tot == 1) & (predictions.prediction == 0)].count()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Malo_Dias_tot', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Define a UDF to extract the second element of the probability vector\n",
        "probability_udf = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Add a 'score' column to the predictions DataFrame\n",
        "predictions = predictions.withColumn('score', probability_udf('probability'))\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = predictions.select('Malo_Dias_tot', 'score').toPandas()\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.stages[-1].featureImportances.toArray()\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "zGYl2NHv3T_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=random_state)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Create a pipeline to chain SMOTE and Decision Tree together\n",
        "pipeline = Pipeline([('smote', smote), ('dt', dt)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using roc_auc_score function\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = pd.DataFrame({'Malo_Dias_tot': y_test, 'score': model.predict_proba(X_test)[:, 1]})\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.named_steps['dt'].feature_importances_\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "QUusNprPaaMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create an ADASYN object\n",
        "adasyn = ADASYN(random_state=random_state)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Create a pipeline to chain ADASYN and Decision Tree together\n",
        "pipeline = Pipeline([('adasyn', adasyn), ('dt', dt)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using roc_auc_score function\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = pd.DataFrame({'Malo_Dias_tot': y_test, 'score': model.predict_proba(X_test)[:, 1]})\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.named_steps['dt'].feature_importances_\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "yxPZErhRc1Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create a TomekLinks object\n",
        "tl = TomekLinks()\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Create a pipeline to chain TomekLinks and Decision Tree together\n",
        "pipeline = Pipeline([('tl', tl), ('dt', dt)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict values for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Calculate AUC using roc_auc_score function\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = pd.DataFrame({'Malo_Dias_tot': y_test, 'score': model.predict_proba(X_test)[:, 1]})\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "\n",
        "# Get the top 10 most important variables of the model\n",
        "importances = model.named_steps['dt'].feature_importances_\n",
        "importance_df = pd.DataFrame(list(zip(feature_cols, importances)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)\n",
        "print(importance_df.head(10))\n"
      ],
      "metadata": {
        "id": "1a1x6cV1eUUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_red = df_2.toPandas()\n",
        "columnas = df_red.columns.tolist()\n",
        "columnas.remove('Malo_Dias_tot')\n",
        "columnas.append('Malo_Dias_tot')\n",
        "df_red = df_red.reundex(columns=columnas)\n",
        "\n",
        "X = df_red.iloc[:,0:27].values\n",
        "y = df_red.iloc[:, 27].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "sc_X = StandarScaled()\n",
        "\n",
        "X_train = sc_x.fit_transform(X_train)\n",
        "X_test = sc_X.transform(x_test)\n",
        "\n",
        "X_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))\n",
        "X_test = np.reshape(x_test, (x_test.shpe[0], x_test.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(30, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "class_weight = {0: 0.5, 1: 2.5}\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20,class_weight=class_weight)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test,y_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "confusion = confusion_matrix(y_tet, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PN9NNSOifsTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "df_red = df_2.toPandas()\n",
        "columnas = df_red.columns.tolist()\n",
        "columnas.remove('Malo_Dias_tot')\n",
        "columnas.append('Malo_Dias_tot')\n",
        "df_red = df_red.reindex(columns=columnas)\n",
        "\n",
        "X = df_red.iloc[:,0:27].values\n",
        "y = df_red.iloc[:, 27].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(30, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "class_weight = {0: 0.5, 1: 2.5}\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20,class_weight=class_weight)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test,y_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "confusion = confusion_matrix(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "sensitivities = np.zeros(X_test.shape[1])\n",
        "for i in range(X_test.shape[1]):\n",
        "    X_test_perturbed = X_test.copy()\n",
        "    X_test_perturbed[:, i] += np.std(X_test[:, i])\n",
        "    y_pred_perturbed = model.predict(X_test_perturbed)\n",
        "    sensitivities[i] = np.mean(np.abs(y_pred_perturbed - y_pred))\n",
        "sorted_idx = np.argsort(sensitivities)[::-1]\n",
        "\n",
        "# Imprimir el ranking de características\n",
        "print(\"Ranking de características:\")\n",
        "for i in sorted_idx:\n",
        "    print(f\"{i}. Característica {i} ({sensitivities[i]:.3f})\")\n",
        "\n",
        "print(f'F1 Score: {f1:.3f}')\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'ROC-AUC: {roc_auc:.3f}')\n"
      ],
      "metadata": {
        "id": "iZyAauyQByh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "df_red = df_2.toPandas()\n",
        "columnas = df_red.columns.tolist()\n",
        "columnas.remove('Malo_Dias_tot')\n",
        "columnas.append('Malo_Dias_tot')\n",
        "df_red = df_red.reindex(columns=columnas)\n",
        "\n",
        "X = df_red.iloc[:,0:27].values\n",
        "y = df_red.iloc[:, 27].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(30, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "class_weight = {0: 0.5, 1: 2.5}\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20,class_weight=class_weight)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test,y_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "confusion = confusion_matrix(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "sensitivities = np.zeros(X_test.shape[1])\n",
        "for i in range(X_test.shape[1]):\n",
        "    X_test_perturbed = X_test.copy()\n",
        "    X_test_perturbed[:, i] += np.std(X_test[:, i])\n",
        "    y_pred_perturbed = model.predict(X_test_perturbed)\n",
        "    sensitivities[i] = np.mean(np.abs(y_pred_perturbed - y_pred))\n",
        "sorted_idx = np.argsort(sensitivities)[::-1]\n",
        "\n",
        "# Imprimir el ranking de características\n",
        "print(\"Ranking de características:\")\n",
        "for i in sorted_idx:\n",
        "    print(f\"{i}. Característica {i} ({sensitivities[i]:.3f})\")\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = pd.DataFrame({'Malo_Dias_tot': y_test,\n",
        "                        'score': model.predict(X_test).ravel()})\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - \\\n",
        "                (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'ROC-AUC: {roc_auc:.3f}')\n"
      ],
      "metadata": {
        "id": "6S_y3UgihHOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "df_red = df_2.toPandas()\n",
        "columnas = df_red.columns.tolist()\n",
        "columnas.remove('Malo_Dias_tot')\n",
        "columnas.append('Malo_Dias_tot')\n",
        "df_red = df_red.reindex(columns=columnas)\n",
        "\n",
        "X = df_red.iloc[:,0:27].values\n",
        "y = df_red.iloc[:, 27].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "class_weight = {0: 0.5, 1: 2.5}\n",
        "\n",
        "model.fit(X_train, y_train, epochs=20,class_weight=class_weight)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test,y_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "confusion = confusion_matrix(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "sensitivities = np.zeros(X_test.shape[1])\n",
        "for i in range(X_test.shape[1]):\n",
        "    X_test_perturbed = X_test.copy()\n",
        "    X_test_perturbed[:, i] += np.std(X_test[:, i])\n",
        "    y_pred_perturbed = model.predict(X_test_perturbed)\n",
        "    sensitivities[i] = np.mean(np.abs(y_pred_perturbed - y_pred))\n",
        "sorted_idx = np.argsort(sensitivities)[::-1]\n",
        "\n",
        "# Imprimir el ranking de características\n",
        "print(\"Ranking de características:\")\n",
        "for i in sorted_idx:\n",
        "    print(f\"{i}. Característica {i} ({sensitivities[i]:.3f})\")\n",
        "\n",
        "# Calculate the KS statistic\n",
        "data_pd = pd.DataFrame({'Malo_Dias_tot': y_test,\n",
        "                        'score': model.predict(X_test).ravel()})\n",
        "data_pd['good'] = (data_pd['Malo_Dias_tot'] == 0).astype(int)\n",
        "data_pd['bad'] = (data_pd['Malo_Dias_tot'] == 1).astype(int)\n",
        "data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "grouped = data_pd.groupby('bucket', as_index=True)\n",
        "kstable = grouped.min().score.to_frame(name='min_score')\n",
        "kstable['max_score'] = grouped.max().score\n",
        "kstable['bads'] = grouped.sum().bad\n",
        "kstable['goods'] = grouped.sum().good\n",
        "kstable = kstable.reset_index()\n",
        "kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - \\\n",
        "                (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "ks_value = kstable.ks.abs().max()\n",
        "\n",
        "print(f'KS Statistic: {ks_value:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')\n",
        "print(f'Accuracy: {accuracy:.3f}')\n",
        "print(f'Confusion Matrix:\\n{confusion}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'ROC-AUC: {roc_auc:.3f}')\n"
      ],
      "metadata": {
        "id": "7xG0A7xGqCWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "# Cargar datos\n",
        "# df_2 = ...\n",
        "\n",
        "# Convertir DataFrame de PySpark a DataFrame de pandas\n",
        "df_2 = df_2.toPandas()\n",
        "\n",
        "X = df_2.iloc[:, df_2.columns != 'Malo_Dias_tot']\n",
        "y = df_2.iloc[:, df_2.columns == 'Malo_Dias_tot']\n",
        "\n",
        "# Aplicar técnicas de remuestreo\n",
        "tl = TomekLinks(sampling_strategy='auto')\n",
        "X_tl, y_tl = tl.fit_resample(X, y)\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_rus, y_rus = rus.fit_resample(X, y)\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "adasyn = ADASYN(sampling_strategy='auto', random_state=42)\n",
        "X_adasyn, y_adasyn = adasyn.fit_resample(X, y)\n",
        "\n",
        "# Graficar resultados\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "\n",
        "ax1, ax2, ax3, ax4 = axes.flatten()\n",
        "\n",
        "ax1.bar(['0', '1'], [sum(y == 0), sum(y == 1)])\n",
        "ax1.set_title(f'Original (Total: {len(y)})')\n",
        "\n",
        "ax2.bar(['0', '1'], [sum(y_tl == 0), sum(y_tl == 1)])\n",
        "ax2.set_title(f'Tomek Links (Total: {len(y_tl)})')\n",
        "\n",
        "ax3.bar(['0', '1'], [sum(y_rus == 0), sum(y_rus == 1)])\n",
        "ax3.set_title(f'Random Undersampling (Total: {len(y_rus)})')\n",
        "\n",
        "ax4.bar(['0', '1'], [sum(y_smote == 0), sum(y_smote == 1)])\n",
        "ax4.set_title(f'SMOTE (Total: {len(y_smote)})')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KAXrBcC1uVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=12345)\n",
        "\n",
        "# Definir características y etiqueta\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Crear el modelo de Random Forest\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=0)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Definir la cuadrícula de parámetros para la validación cruzada\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Definir el evaluador para la validación cruzada\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Crear el objeto de validación cruzada\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Ajustar el modelo en los datos de entrenamiento\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Realizar predicciones en los datos de prueba\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calcular las métricas ROC-AUC y precisión\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Matriz de confusión:\\n{confusion_matrix}\")\n",
        "\n",
        "# Calcular el recall y la puntuación F1 manualmente\n",
        "TP = confusion_matrix[1, 1]\n",
        "FP = confusion_matrix[0, 1]\n",
        "FN = confusion_matrix[1, 0]\n",
        "precision_manual = TP / (TP + FP)\n",
        "recall_manual = TP / (TP + FN)\n",
        "f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "print(f\"Recall (calculado manualmente): {recall_manual:.3f}\")\n",
        "print(f\"F1 (calculado manualmente): {f1_manual:.3f}\")\n",
        "\n",
        "# Obtener las variables más importantes\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Variables más importantes:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"Estadístico KS: {ks_value:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "K1nLuQjNtlQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "import pandas as pd\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Convert the training data to a Pandas DataFrame\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "# Separate the features and label\n",
        "X = train_pd[features]\n",
        "y = train_pd['label']\n",
        "\n",
        "# Perform NearMiss undersampling\n",
        "nm = NearMiss()\n",
        "X_resampled, y_resampled = nm.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data back to a PySpark DataFrame\n",
        "train_undersampled_pd = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "train_undersampled = spark.createDataFrame(train_undersampled_pd)\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the undersampled training data\n",
        "model = cv.fit(train_undersampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "print(f\"Confusion matrix:\\n{confusion_matrix}\")\n",
        "\n",
        "# Manually calculate recall and F1 score\n",
        "TP = confusion_matrix[1, 1]\n",
        "FP = confusion_matrix[0, 1]\n",
        "FN = confusion_matrix[1, 0]\n",
        "precision_manual = TP / (TP + FP)\n",
        "recall_manual = TP / (TP + FN)\n",
        "f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "print(f\"Recall (manually calculated): {recall_manual:.3f}\")\n",
        "print(f\"F1 (manually calculated): {f1_manual:.3f}\")\n",
        "\n",
        "# Get the most important features\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Most important features:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "score_udf=udf(lambda v:float(v[0]),DoubleType())\n",
        "predictions=predictions.withColumn('score',score_udf('rawPrediction'))\n",
        "ks_value=calc_ks(predictions)\n",
        "print(f\"KS statistic: {ks_value:.3f}\")\n"
      ],
      "metadata": {
        "id": "zVGVDz7V1Fe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}